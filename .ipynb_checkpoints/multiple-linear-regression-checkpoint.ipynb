{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Introduction to Multiple Linear Regression\n",
    "\n",
    "_Authors: TMTC_ | _RUH_\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "\n",
    "### Overview of Supervised Learning\n",
    "---\n",
    "\n",
    "![Supervised learning diagram](./images/supervised_learning.png)\n",
    "\n",
    "As we discussed yesterday:\n",
    "_Simple linear regression (SLR) has one independent variable._\n",
    "\n",
    "_Multivariable (MLR) has potentially infinite independent variables._\n",
    "\n",
    "#### In either case, we are looking to minimize the difference between our predictions, $\\hat{y}$, and the true value, $y$\n",
    "\n",
    "![Estimating coefficients](./images/estimating_coefficients.png)\n",
    "\n",
    "In the diagram above:\n",
    "\n",
    "- The black dots are the **observed values** of x and y.\n",
    "- The blue line is our **least squares line**.\n",
    "- The red lines are the **residuals**, which are the vertical distances between the observed values and the least squares line.\n",
    "\n",
    "\n",
    "### Form of Linear Regression\n",
    "\n",
    "Simple LR uses one feature and a constant to represent a relationship with another feature.\n",
    "### $y = \\alpha + \\beta X +\\epsilon_i $ \n",
    "\n",
    "but you might know it as\n",
    "### $ y = mx + b$\n",
    "\n",
    "And we can extend the simple linear regression into the multiple linear regression (more on this later):\n",
    "### $y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n + \\epsilon_i$\n",
    "\n",
    "- $y$ is the response (the target/outcome/dependent variable)\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for $x_1$ (the first feature/independet variable)\n",
    "- $\\beta_n$ is the coefficient for $x_n$ (the nth feature/independent)\n",
    "- $\\epsilon_i$ is the constant error\n",
    "\n",
    "The $\\beta$ values are called the **model coefficients**:\n",
    "\n",
    "- These values are estimated (or \"learned\") during the model fitting process using the **least squares criterion**.\n",
    "- Specifically, we are finding the line (mathematically) which minimizes the **sum of squared residuals** (or \"sum of squared errors\").\n",
    "- And once we've learned these coefficients, we can use the model to predict the response and draw inferences about the relationships between variables and the outcome.\n",
    "\n",
    "![Estimating coefficients](./images/estimating_coefficients.png)\n",
    "\n",
    "In the diagram above:\n",
    "\n",
    "- The black dots are the **observed values** of x and y.\n",
    "- The blue line is our **least squares line**.\n",
    "- The red lines are the **residuals**, which are the vertical distances between the observed values and the least squares line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SLR in `sklearn`\n",
    "** Walk through the process for fitting a model in `sklearn` **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `sklearn` process\n",
    "\n",
    "When we model data using `sklearn`, we're going to follow (more or less) the same process every time.\n",
    "\n",
    "1. Select and instantiate the algorithm we want to use (i.e., `from [library] import [model]`)\n",
    "2. Create a feature matrix (called 'X' for convenience) with your independent variable(s)\n",
    "2. Create an outcome/targe/response matrix (usually denoted 'y') with your dependent variable\n",
    "3. Ensure that X and y are the same length (.shape is your friend here)\n",
    "4. Instantiate the estimator\n",
    "5. Fit the estimator (i.e., train your model)\n",
    "6. Use the estimator to make predictions\n",
    "7. Evaluate the predictions using the appropriate metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = './datasets/bikeshare.csv'\n",
    "bikes = pd.read_csv(url, index_col='datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "| Variable| Description |\n",
    "|---------|----------------|\n",
    "|datetime| hourly date + timestamp  |\n",
    "|season|  1 = spring, 2 = summer, 3 = fall, 4 = winter |\n",
    "|holiday| whether the day is considered a holiday|\n",
    "|workingday| whether the day is neither a weekend nor holiday|\n",
    "|weather| 1: Clear, 2: Mist, 3: Light Snow 4: Heavy Rain|\n",
    "|temp| temperature in Celsius|\n",
    "|atemp| \"feels like\" temperature in Celsius|\n",
    "|humidity| relative humidity|\n",
    "|windspeed| wind speed|\n",
    "|casual| number of non-registered user rentals initiated|\n",
    "|registered| number of registered user rentals initiated|\n",
    "|count| number of total rentals|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some eda\n",
    "bikes.rename(columns={'count':'total'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: Select and instantiate the algorithm we want to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# step 2: Create a feature matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check linear relationship\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: Create a feature matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: Ensure that X and y are the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check X type , shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check y type,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5: Instantiate the estimator\n",
    "lr= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6: Fit the estimator (train your model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 7: Use the estimator to make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 8: Evaluate the predictions using the appropriate metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check coef\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression in `sklearn`\n",
    "---\n",
    "We've built a simple linear regression, one using only one feature, and it's pretty useful. But is it likely that only one feature is going be accurate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"adding-more-features-to-the-model\"></a>\n",
    "### Adding More Features to the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, one variable explained the variance of another; however, more often than not, we will need multiple variables. \n",
    "\n",
    "- For example, a house's price may be best measured by square feet, but a lot of other variables play a vital role: bedrooms, bathrooms, location, appliances, etc. \n",
    "\n",
    "- For a linear regression, we want these variables to be largely independent of one another, but all of them should help explain the y variable.\n",
    "\n",
    "We'll work with bikeshare data to showcase what this means and to explain a concept called multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Explore more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: Create a feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlation again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature column variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check linear relationship\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: Create a feature matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: Ensure that X and y are the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check X type , shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check y type,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5: Instantiate the estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6: Fit the estimator (train your model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 7: Use the estimator to make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 8: Evaluate the predictions using the appropriate metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check coef (Pair the feature names with the coefficients.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the coefficients:\n",
    "\n",
    "- Holding all other features fixed, a 1-unit increase in temperature is associated with a rental increase of 2.64 bikes.\n",
    "- Holding all other features fixed, a 1-unit increase in temperature (feels like) is associated with a rental increase of 4.87 bikes.\n",
    "- Holding all other features fixed, a 1-unit increase in humidity is associated with a rental decrease of 3.16 bikes.\n",
    "- Holding all other features fixed, a 1-unit increase in season is associated with a rental increase of 22.3 bikes.\n",
    "- Holding all other features fixed, a 1-unit increase in weather is associated with a rental increase of 7.38 bikes.\n",
    "\n",
    "\n",
    "Does anything look incorrect and does not reflect reality?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-is-multicollinearity\"></a>\n",
    "## What Is Multicollinearity?\n",
    "---\n",
    "\n",
    "Multicollinearity happens when two or more features are highly correlated with each other. The problem is that due to the high correlation, it's hard to disambiguate which feature has what kind of effect on the outcome. In other words, the features mask each other. \n",
    "\n",
    "There is a second related issue called variance inflation where including correlated features increases the variability of our model and p-values by widening the standard errors. This can be measured with the variance inflation factor, which we will not cover here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With the bikeshare data, let's compare three data points: actual temperature, \"feel\" temperature, and guest ridership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assumptions'></a>\n",
    "\n",
    "## Assumptions of MLR\n",
    "\n",
    "---\n",
    "\n",
    "Like SLR, there are assumptions associated with MLR. Luckily, they're quite similar to the SLR assumptions.\n",
    "\n",
    "1. **Linearity:** $Y$ must have an approximately linear relationship with each independent $X_i$.\n",
    "2. **Independence:** Errors (residuals) $\\varepsilon_i$ and $\\varepsilon_j$ must be independent of one another for any $i \\ne j$.\n",
    "3. **Normality:** The errors (residuals) follow a Normal distribution with mean 0.\n",
    "4. **Equality of Variances**: The errors (residuals) should have a roughly consistent pattern, regardless of the value of the $X_i$ predictors. (There should be no discernable relationship between the $X$ predictors and the residuals.)\n",
    "5. **Independence of Predictors**: The independent variables $X_i$ and $X_j$ must be independent of one another for any $i \\ne j$.\n",
    "\n",
    "The mnemonic LINEI is a useful way to remember these five assumptions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
